---
title: "Predicting US Airline Passenger Satisfaction: A Data-Driven Approach."
author: "Hrayr Muradyan, Azin Piran, Sopuruchi Chisom, Shengjia Yu."
date: "2024/12/07"
jupyter: python3
format: 
    html:
        toc: true
        toc-depth: 2
    pdf:
        toc: true
        toc-depth: 2
        fig-pos: 'h'
bibliography: references.bib
citation: true
execute:
  echo: false
  warning: false
editor: source
---

```{python}
import pandas as pd
test_scores = pd.read_csv("../results/tables/test_scores.csv")
test_scores_rounded = test_scores.round(2)
```
\newpage

# **Summary**
This project develops a classification model using a decision tree algorithm to predict airline customer satisfaction based on various factors, 
including in-flight service quality and customer demographic information. In this context, customer satisfaction refers to the overall experience and perception of the airline services by passengers. 
The study aimed to categorize customers into two distinct groups: those who are satisfied (denoted as "satisfied") and those who are neutral or dissatisfied (denoted as "neutral or dissatisfied").
The best decision tree model was evaluated on an unseen test dataset, demonstrating strong overall F1-score of `{python} test_scores_rounded.loc[0, 'F1-Score']`.

These results indicate that the model effectively detects patterns in customer satisfaction,
making it a valuable tool for analyzing key factors that influence satisfaction. 
While the results are very promising, there are several limitations of the project that should be addressed. 
Firstly, the dataset contains only US airline observations which limits its usage to only US-based airline scenarios. 
Secondly, the dataset is relatively old, being about 5 years old. The airline industry might have faced significant changes.
Thirdly, collecting detailed information about customer experiences, such as seat comfort ratings, can be challenging. 
And lastly, the exact method customer satisfaction was measured is unknown.
Future efforts should prioritize collecting a new dataset that includes international airlines, as well as exploring alternative methods for quantifying subjective customer satisfaction.


# **Introduction**
In the highly competitive field of air transport management, passenger satisfaction plays a critical role in making customer loyalty, 
providing operational insights, enhancing financial performance, and ensuring compliance with regulations and rankings (@Eshaghi2024).
Passenger satisfaction is typically a subjective measure reflecting how well an airline meets or exceeds customer expectations.
It can be evaluated through various metrics, including binary classifications (e.g., satisfied vs. dissatisfied). 
While there are numerous studies held on factors influencing customer satisfaction like service quality (@Namukasa2013), 
it is very important to be able to predict the customer satisfaction with high accuracy for understanding how to improve and make better decisions. 
This study aims to create a reliable binary classification model with high performance to distinguish between satisfied and dissatisfied customers.
To achieve the goal we employ a comprehensive dataset which contains different features convering a variety of attributes such as
flight information, passenger demographics, and service quality ratings.

\newpage

# **Methods**

```{python}
import pandas as pd
combined_dataset = pd.read_csv("../data/combined_dataset.csv")
```

## **Dataset**
The dataset used to answer this question was sourced in Kaggle, posted by @Klein2020. 
It is important to note that the dataset was originally posted by @johndddddd, 
which is then modified and cleaned by @Klein2020. 
Thought the exact origin of the dataset is unknown, it consists of **only** US airline data, as mentioned in the original source.
It contains `{python} combined_dataset.shape[1]` columns and `{python} "{:,}".format(combined_dataset.shape[0])` observations where each observation in the dataset 
contains a variety of information about the flight information, passenger demographics, flight service quality, etc.
The full dataset can be found [here](https://www.kaggle.com/datasets/teejmahal20/airline-passenger-satisfaction). 

## **Analysis**

After the dataset examination some features were removed from the analysis including ID and arrival_delay_in_minutes,
where ID is a unique identifier column and arrival_delay_in_minutes contains the same information as departure_delay_in_minutes. 
The dataset contained variety of data types including numeric, nominal categorical and ordinal categorical that were already encoded into integers.
The analysis assumed that the distances between the levels of the ordinal variables are consistent and equal.
All data types were properly encoded and preprocessed using StandardScaler for numeric variables,
OneHotEncoder for nominal categorical variables and MinMaxScaler for ordinal categorical variables.
The dataset was initially split into train and test sets, which was combined and splitted to have control over the splitting strategy.
Train dataset contained the 80% of the observations and the test set the rest 20%.
Decision Tree Classifier was fitted to distinguish between satisfied and unsatisfied customers.
Decision Trees are particularly easy to understand, interpret, and visualize, while effectively handling both numerical and categorical data. 
Additionally, they can capture non-linear relationships, which make them the best option for different tasks.
The selection of the algorithm also comes from the fact that among other simple models Decision Trees provided the best results.
Thus, while decision trees do not require scaling because they split data based on feature thresholds rather than distance metrics, 
the preprocessed data is intended for use with other models (e.g., SVM or logistic regression) that depend on scaling. 
It ensures consistency across the pipeline and simplifies data management when experimenting with multiple algorithms.
Variety of metrics were used to train the model and assess the model's performance.
F1-score was used to tune the hyperparameters using Grid Search and Cross-Validation with 30-folds.
The Python programming language (@van1995python) is used for conducting the analysis using a variety of packages including
but now limited to Pandas (@McKinney2010), scikit-learn (@Pedregosa2011) and matplotlib (@Hunter2007).

## **Results**

The random splitting of the dataset resulted in a representative distribution of the target variable across train and test sets.
After examining the target distribution of the train dataset it was noticed that there are slightly more dissatisfied observations
in the dataset than satisfied. The target distribution plot below (see @fig-target_variable_distribution) shows that the train dataset contains 58,830 dissatisfied
observations and 45,074 satisfied observations.

![Target variable distribution.](../results/figures/target_variable_distribution.png){#fig-target_variable_distribution width=80%}

To understand how different variables relate to the target variable and if they might be useful for prediction,
multiple bivariate checks are done. Data visualization techniques are used to assess the relationship between exploratory variables and the target variable.
Density plots for continuous features revealed slightly different distributions across customer satisfaction levels.
For instance, people who are dissatisfied on average are younger than those who are older.
Additionally, customers on average are more satisfied with longer distances flights on average.
On the other hand, departure delay on average can have a bit negative effect on the satisfaction.
See figure @fig-numeric_feat_target_plots for more insights.

![The density distributions of numeric features against a binary target variable.](../results/figures/numeric_feat_target_plots.png){#fig-numeric_feat_target_plots width=100%}

Count plots for categorical variables illustrated how to frequency of specific categories differed between
satisfied and dissatisfied customers (See figure @fig-cat_feat_target_plots). Variables like seat comfort, leg room, cleanliness and inflight entertainment
show clear patterns. These findings suggest that these features are not only intuitively aligned with customer expectations 
but also serve as important predictors in the model. The clear association may help the model to distinguish between
the class quite effectively.

\newpage
![The countplots of the categorical variables against a binary target variable.](../results/figures/cat_feat_target_plots.png){#fig-cat_feat_target_plots width=100%}

The correlation matrix in Figure @fig-correlation_matrix is also examined to see if there are anomalous correlations (or multicollinearity) between 
different exploratory variables. Particularly correlations higher than 0.9 were checked. 
It is important to note that the scaled dataset was used to compute the correlation between numeric variables.
While there are features that are correlated at some extent, none of them is critical. 
Thus, no features are removed based on the correlations. 

![Heatmap of correlations between numeric predictors.](../results/figures/correlation_matrix.png){#fig-correlation_matrix width=100%}

```{python}
import pandas as pd
cv_results = pd.read_csv("../results/tables/cv_results.csv")
```

A decision tree classifier was trained to achieve a nonlinear separation between the classes.
To optimize the default model even further and limit the overfitting, the max_depth hyperparameter was tuned
using a 30-fold cross-validation strategy. F1-Score was used as the metric for tuning to account for the small imbalance
in the dataset. The figure @fig-cv_results_plot shows the performance of train and validation sets across different hyperparameter values.
The best performing model was achieved using a max_depth of `{python} cv_results.loc[cv_results['mean_val_score'].idxmax(), 'param_decisiontreeclassifier__max_depth']`,
balancing bias and variance effectively. The tuned model produced a robust predicting performance

![Cross-validation results plot for different values of parameter max_depth.](../results/figures/cv_results_plot.png){#fig-cv_results_plot width=80%}

Our model performed well on unseen, test data with impressive F1-score of `{python} test_scores_rounded.loc[0, 'F1-Score']`. 
The classification report @tbl-classification_report shows the performance details even further. 
This results are promising and suggest that the model could be highly useful in identifying satisfied and dissatisfied customers. 
The high F1-score indicates a good balance between precision and recall, ensuring that the model balances effectively across the categories.

```{python}
#| label: tbl-classification_report
#| tbl-cap: Classification report for the test data set
classification_report = pd.read_csv("../results/tables/classification_report.csv")
classification_report_rounded = classification_report.round(2)
classification_report_rounded

```

The results in the confusion matrix @fig-confusion_matrix shows how well it predicts each class.

![Confusion matrix of the predictions of the test data set](../results/figures/confusion_matrix.png){#fig-confusion_matrix width=80%}

The exact performance measures can be found in the table @tbl-test_scores which evaluate the performance of the model across variety of metrics
including Accuracy, Recall, Precision and F1-Score.
```{python}
#| label: tbl-test_scores
#| tbl-cap: Test Scores
test_scores_rounded

```

The model achieved strong performance on the test dataset, with an accuracy of `{python} test_scores_rounded.loc[0, 'Accuracy']`. 
It demonstrated high precision `{python} test_scores_rounded.loc[0, 'Precision']` in predicting "satisfied" passengers, 
meaning most of its positive predictions were correct. The recall was `{python} test_scores_rounded.loc[0, 'Recall']`, 
indicating the model successfully identified most "satisfied" passengers, though there is slight room for improvement. 
The F1-score of `{python} test_scores_rounded.loc[0, 'F1-Score']` reflects a good balance between precision and recall, indicating overall reliable performance.

While the results are very promising, there are several limitations of the project that should be addressed. 
Firstly, the dataset contains only US airline observations which limits its usage to only US-based airline scenarios.
This geographic limitation reduces the generalizability of the model to international airlines or those operating in different regulatory and market environments.
Secondly, the dataset is relatively old, being about 5 years old. 
The airline industry might have faced significant changes, especially after COVID-19 period which could
shift the customer expectations and factors affecting satisfaction.
Thirdly, collecting detailed information about customer experiences, such as seat comfort ratings, can be challenging. 
These subjective ratings are often difficult to obtain, especially on a large scale.
Finally, the way customer satisfaction was measured is unknown, as different people have different expectations.
To address this limitations, we suggest collecting a new data set involving international airlines. 
Additionally, further research could explore alternative ways to quantify subjective binary customer satisfaction target.

\newpage

## **References**